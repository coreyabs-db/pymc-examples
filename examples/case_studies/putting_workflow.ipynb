{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(putting_workflow)=\n",
    "# Model building and expansion for golf putting\n",
    "\n",
    ":::{post} Apr 2, 2022\n",
    ":tags: Bayesian workflow, model expansion, sports \n",
    ":category: intermediate, how-to\n",
    ":author: Colin Carroll, Marco Gorelli, Oriol Abril-Pla\n",
    ":::\n",
    "\n",
    "**This uses and closely follows [the case study from Andrew Gelman](https://mc-stan.org/users/documentation/case-studies/golf.html), written in Stan. There are some new visualizations and we steered away from using improper priors, but much credit to him and to the Stan group for the wonderful case study and software.**\n",
    "\n",
    "We use a data set from \"Statistics: A Bayesian Perspective\" {cite:p}`berry1996statistics`. The dataset describes the outcome of professional golfers putting from a number of distances, and is small enough that we can just print and load it inline, instead of doing any special `csv` reading.\n",
    "\n",
    ":::{include} ../extra_installs.md\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import xarray as xr\n",
    "\n",
    "from xarray_einstats.stats import XrContinuousRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golf putting data from berry (1996)\n",
    "golf_data = \"\"\"distance tries successes\n",
    "2 1443 1346\n",
    "3 694 577\n",
    "4 455 337\n",
    "5 353 208\n",
    "6 272 149\n",
    "7 256 136\n",
    "8 240 111\n",
    "9 217 69\n",
    "10 200 67\n",
    "11 237 75\n",
    "12 202 52\n",
    "13 192 46\n",
    "14 174 54\n",
    "15 167 28\n",
    "16 201 27\n",
    "17 195 31\n",
    "18 191 33\n",
    "19 147 20\n",
    "20 152 24\"\"\"\n",
    "\n",
    "\n",
    "golf_data = pd.read_csv(io.StringIO(golf_data), sep=\" \", dtype={\"distance\": \"float\"})\n",
    "\n",
    "BALL_RADIUS = (1.68 / 2) / 12\n",
    "CUP_RADIUS = (4.25 / 2) / 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start plotting the data to get a better idea of how it looks. The hidden cell contains the plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_golf_data(golf_data, ax=None, color=\"C0\"):\n",
    "    \"\"\"Utility function to standardize a pretty plotting of the golf data.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    bg_color = ax.get_facecolor()\n",
    "    rv = st.beta(golf_data.successes, golf_data.tries - golf_data.successes)\n",
    "    ax.vlines(golf_data.distance, *rv.interval(0.68), label=None, color=color)\n",
    "    ax.plot(\n",
    "        golf_data.distance,\n",
    "        golf_data.successes / golf_data.tries,\n",
    "        \"o\",\n",
    "        mec=color,\n",
    "        mfc=bg_color,\n",
    "        label=None,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Distance from hole\")\n",
    "    ax.set_ylabel(\"Percent of putts made\")\n",
    "    ax.set_ylim(bottom=0, top=1)\n",
    "\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.grid(True, axis=\"y\", alpha=0.7)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_golf_data(golf_data)\n",
    "ax.set_title(\"Overview of data from Berry (1996)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After plotting, we see that generally golfers are less accurate from further away. Note that this data is pre-aggregated: we may be able to do more interesting work with granular putt-by-putt data. This data set appears to have been binned to the nearest foot.\n",
    "\n",
    "We might think about doing prediction with this data: fitting a curve to this data would allow us to make reasonable guesses at intermediate distances, as well as perhaps to extrapolate to longer distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit model\n",
    "\n",
    "First we will fit a traditional logit-binomial model. We model the number of successes directly, with\n",
    "\n",
    "$$\n",
    "a, b \\sim \\mathcal{N}(0, 1) \\\\\n",
    "p(\\text{success}) = \\operatorname{logit}^{-1}(a \\cdot \\text{distance} + b) \\\\\n",
    "\\text{num. successes} \\sim \\operatorname{Binomial}(\\text{tries}, p(\\text{success}))\n",
    "$$\n",
    "\n",
    "Here is how to write that model in PyMC. We use underscore appendices in our model variables to avoid polluting the namespace. We also use {class}`pymc.MutableData` to let us swap out the data later, when we will work with a newer data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logit_model:\n",
    "    distance_ = pm.MutableData(\"distance\", golf_data[\"distance\"], dims=\"obs_id\")\n",
    "    tries_ = pm.MutableData(\"tries\", golf_data[\"tries\"], dims=\"obs_id\")\n",
    "    successes_ = pm.MutableData(\"successes\", golf_data[\"successes\"], dims=\"obs_id\")\n",
    "\n",
    "    a_ = pm.Normal(\"a\")\n",
    "    b_ = pm.Normal(\"b\")\n",
    "\n",
    "    pm.Binomial(\n",
    "        \"success\",\n",
    "        n=tries_,\n",
    "        p=pm.math.invlogit(a_ * distance_ + b_),\n",
    "        observed=successes_,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(logit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some intuition that $a$ should be negative, and also that $b$ should be positive (since when $\\text{distance} = 0$, we expect to make nearly 100% of putts). We are not putting that into the model, though. We are using this as a baseline, and we may as well wait and see if we need to add stronger priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logit_model:\n",
    "    logit_trace = pm.sample(1000, tune=1000, target_accept=0.9)\n",
    "\n",
    "az.summary(logit_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see $a$ and $b$ have the signs we expected. There were no bad warnings emitted from the sampler. Looking at the summary, the number of effective samples is reasonable, and the rhat is close to 1. This is a small model, so we are not being too careful about inspecting the fit.\n",
    "\n",
    "We plot 50 posterior draws of $p(\\text{success})$ along with the expected value. Also, we draw 500 points from the posterior predictive to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw posterior predictive samples\n",
    "with logit_model:\n",
    "    logit_trace.extend(pm.sample_posterior_predictive(logit_trace))\n",
    "\n",
    "# hard to plot more than 400 sensibly\n",
    "logit_post = az.extract(logit_trace, num_samples=400)\n",
    "logit_ppc = az.extract(logit_trace, group=\"posterior_predictive\", num_samples=400)\n",
    "const_data = logit_trace[\"constant_data\"]\n",
    "\n",
    "logit_ppc_success = logit_ppc[\"success\"] / const_data[\"tries\"]\n",
    "\n",
    "# Plotting\n",
    "ax = plot_golf_data(golf_data)\n",
    "t_ary = np.linspace(CUP_RADIUS - BALL_RADIUS, golf_data.distance.max(), 200)\n",
    "t = xr.DataArray(t_ary, coords=[(\"distance\", t_ary)])\n",
    "logit_post[\"expit\"] = scipy.special.expit(logit_post[\"a\"] * t + logit_post[\"b\"])\n",
    "\n",
    "ax.plot(\n",
    "    t,\n",
    "    logit_post[\"expit\"].T,\n",
    "    lw=1,\n",
    "    color=\"C1\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.plot(t, logit_post[\"expit\"].mean(dim=\"sample\"), color=\"C2\")\n",
    "\n",
    "ax.plot(golf_data.distance, logit_ppc_success, \"k.\", alpha=0.01)\n",
    "ax.set_title(\"Logit mean and posterior predictive\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is ok, but not great! It is a good start for a baseline, and lets us answer curve-fitting type questions. We may not trust much extrapolation beyond the end of the data, especially given how the curve does not fit the last four values very well. For example, putts from 50 feet are expected to be made with probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_at_50 = scipy.special.expit(logit_post[\"a\"] * 50 + logit_post[\"b\"]).mean(dim=\"sample\").item()\n",
    "print(f\"{100 * prob_at_50:.5f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lesson from this is that\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[f(\\theta)] \\ne f(\\mathbb{E}[\\theta]).\n",
    "$$\n",
    "\n",
    "this appeared here in using\n",
    "\n",
    "```python\n",
    "# Right!\n",
    "scipy.special.expit(logit_trace.posterior[\"a\"] * 50 + logit_trace.posterior[\"b\"]).mean(dim=\"sample\")\n",
    "```\n",
    "rather than\n",
    "\n",
    "```python\n",
    "# Wrong!\n",
    "scipy.special.expit(logit_trace.posterior[\"a\"].mean(dim=\"sample\") * 50 + logit_trace.posterior[\"b\"].mean(dim=\"sample\"))\n",
    "```\n",
    "\n",
    "to calculate our expectation at 50 feet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry-based model\n",
    "\n",
    "As a second pass at modelling this data, both to improve fit and to increase confidence in extrapolation, we think about the geometry of the situation. We suppose professional golfers can hit the ball in a certain direction, with some small(?) error. Specifically, the angle the ball actually travels is normally distributed around 0, with some variance that we will try to learn.\n",
    "\n",
    "Then the ball goes in whenever the error in angle is small enough that the ball still hits the cup. This is intuitively nice! A longer putt will admit a smaller error in angle, and so a lower success rate than for shorter putts.\n",
    "\n",
    "I am skipping a derivation of the probability of making a putt given the accuracy variance and distance to the hole, but it is a fun exercise in geometry, and turns out to be\n",
    "\n",
    "$$\n",
    "p(\\text{success} | \\sigma_{\\text{angle}}, \\text{distance}) = 2 \\Phi\\left( \\frac{ \\arcsin \\left((R - r) / \\text{distance}\\right)}{\\sigma_{\\text{angle}}}\\right),\n",
    "$$\n",
    "\n",
    "where $\\Phi$ is the normal cumulative density function, $R$ is the radius of the cup (turns out 2.125 inches), and $r$ is the radius of the golf ball (around 0.84 inches).\n",
    "\n",
    "To get a feeling for this model, let's look at a few manually plotted values for $\\sigma_{\\text{angle}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_angle_model(variances_of_shot, t):\n",
    "    norm_dist = XrContinuousRV(st.norm, 0, variances_of_shot)\n",
    "    return 2 * norm_dist.cdf(np.arcsin((CUP_RADIUS - BALL_RADIUS) / t)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "var_shot_ary = [0.01, 0.02, 0.05, 0.1, 0.2, 1]\n",
    "var_shot_plot = xr.DataArray(var_shot_ary, coords=[(\"variance\", var_shot_ary)])\n",
    "\n",
    "forward_angle_model(var_shot_plot, t).plot.line(hue=\"variance\")\n",
    "\n",
    "plot_golf_data(golf_data, ax=ax)\n",
    "ax.set_title(\"Model prediction for selected amounts of variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a promising approach! A variance of 0.02 radians looks like it will be close to the right answer. The model also predicted that putts from 0 feet all go in, which is a nice side effect. We might think about whether a golfer misses putts symmetrically. It is plausible that a right handed putter and a left handed putter might have a different bias to their shots.\n",
    "### Fitting the model\n",
    "\n",
    "PyMC has $\\Phi$ implemented, but it is pretty hidden (`pm.distributions.dist_math.normal_lcdf`), and it is worthwhile to implement it ourselves anyways, using an identity with the [error function](https://en.wikipedia.org/wiki/Error_function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    \"\"\"Calculates the standard normal cumulative distribution function.\"\"\"\n",
    "    return 0.5 + 0.5 * pt.erf(x / pt.sqrt(2.0))\n",
    "\n",
    "\n",
    "with pm.Model() as angle_model:\n",
    "    distance_ = pm.MutableData(\"distance\", golf_data[\"distance\"], dims=\"obs_id\")\n",
    "    tries_ = pm.MutableData(\"tries\", golf_data[\"tries\"], dims=\"obs_id\")\n",
    "    successes_ = pm.MutableData(\"successes\", golf_data[\"successes\"], dims=\"obs_id\")\n",
    "\n",
    "    variance_of_shot = pm.HalfNormal(\"variance_of_shot\")\n",
    "    p_goes_in = pm.Deterministic(\n",
    "        \"p_goes_in\",\n",
    "        2 * phi(pt.arcsin((CUP_RADIUS - BALL_RADIUS) / distance_) / variance_of_shot) - 1,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "    success = pm.Binomial(\"success\", n=tries_, p=p_goes_in, observed=successes_, dims=\"obs_id\")\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(angle_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Predictive Checks\n",
    "\n",
    "We often wish to sample from the prior, especially if we have some idea of what the observations would look like, but not a lot of intuition for the prior parameters. We have an angle-based model here, but it might not be intuitive if the *variance* of the angle is given, how that effects the accuracy of a shot. Let's check!\n",
    "\n",
    "Sometimes a custom visualization or dashboard is useful for a prior predictive check. Here, we plot our prior distribution of putts from 20 feet away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with angle_model:\n",
    "    angle_trace = pm.sample_prior_predictive(500)\n",
    "\n",
    "angle_prior = angle_trace.prior.squeeze()\n",
    "\n",
    "angle_of_shot = XrContinuousRV(st.norm, 0, angle_prior[\"variance_of_shot\"]).rvs(\n",
    "    random_state=RANDOM_SEED\n",
    ")  # radians\n",
    "distance = 20  # feet\n",
    "\n",
    "end_positions = xr.Dataset(\n",
    "    {\"endx\": distance * np.cos(angle_of_shot), \"endy\": distance * np.sin(angle_of_shot)}\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for draw in end_positions[\"draw\"]:\n",
    "    end = end_positions.sel(draw=draw)\n",
    "    ax.plot([0, end[\"endx\"]], [0, end[\"endy\"]], \"k-o\", lw=1, mfc=\"w\", alpha=0.5)\n",
    "ax.plot(0, 0, \"go\", label=\"Start\", mfc=\"g\", ms=20)\n",
    "ax.plot(distance, 0, \"ro\", label=\"Goal\", mfc=\"r\", ms=20)\n",
    "\n",
    "ax.set_title(f\"Prior distribution of putts from {distance}ft away\")\n",
    "\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little funny! Most obviously, it should probably be not this common to putt the ball *backwards*. This also leads us to worry that we are using a normal distribution to model an angle. The [von Mises](https://en.wikipedia.org/wiki/Von_Mises_distribution) distribution may be appropriate here. Also, the golfer needs to stand somewhere, so perhaps adding some bounds to the von Mises would be appropriate. We will find that this model learns from the data quite well, though, and these additions are not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with angle_model:\n",
    "    angle_trace.extend(pm.sample(1000, tune=1000, target_accept=0.85))\n",
    "\n",
    "angle_post = az.extract(angle_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_golf_data(golf_data)\n",
    "\n",
    "angle_post[\"expit\"] = forward_angle_model(angle_post[\"variance_of_shot\"], t)\n",
    "\n",
    "ax.plot(\n",
    "    t,\n",
    "    angle_post[\"expit\"][:, ::100],\n",
    "    lw=1,\n",
    "    color=\"C1\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    t,\n",
    "    angle_post[\"expit\"].mean(dim=\"sample\"),\n",
    "    label=\"Geometry-based model\",\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    t,\n",
    "    logit_post[\"expit\"].mean(dim=\"sample\"),\n",
    "    label=\"Logit-binomial model\",\n",
    ")\n",
    "ax.set_title(\"Comparing the fit of geometry-based and logit-binomial model\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model appears to fit much better, and by modelling the geometry of the situation, we may have a bit more confidence in extrapolating the data. This model suggests that a 50 foot putt has much higher chance of going in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_prob_at_50 = forward_angle_model(angle_post[\"variance_of_shot\"], np.array([50]))\n",
    "print(f\"{100 * angle_prob_at_50.mean().item():.2f}% vs {100 * prob_at_50:.5f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also recreate our prior predictive plot, giving us some confidence that the prior was not leading to unreasonable situations in the posterior distribution: the variance in angle is quite small!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_of_shot = XrContinuousRV(st.norm, 0, angle_post[\"variance_of_shot\"]).rvs(\n",
    "    random_state=RANDOM_SEED\n",
    ")  # radians\n",
    "distance = 20  # feet\n",
    "\n",
    "end_positions = xr.Dataset(\n",
    "    {\"endx\": distance * np.cos(angle_of_shot.data), \"endy\": distance * np.sin(angle_of_shot.data)}\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for x, y in zip(end_positions.endx, end_positions.endy):\n",
    "    ax.plot([0, x], [0, y], \"k-o\", lw=1, mfc=\"w\", alpha=0.5)\n",
    "ax.plot(0, 0, \"go\", label=\"Start\", mfc=\"g\", ms=20)\n",
    "ax.plot(distance, 0, \"ro\", label=\"Goal\", mfc=\"r\", ms=20)\n",
    "\n",
    "ax.set_title(f\"Prior distribution of putts from {distance}ft away\")\n",
    "ax.set_xlim(-21, 21)\n",
    "ax.set_ylim(-21, 21)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data!\n",
    "\n",
    "Mark Broadie used new summary data on putting to fit a new model. We will use this new data to refine our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  golf putting data from Broadie (2018)\n",
    "new_golf_data = \"\"\"distance tries successes\n",
    "0.28 45198 45183\n",
    "0.97 183020 182899\n",
    "1.93 169503 168594\n",
    "2.92 113094 108953\n",
    "3.93 73855 64740\n",
    "4.94 53659 41106\n",
    "5.94 42991 28205\n",
    "6.95 37050 21334\n",
    "7.95 33275 16615\n",
    "8.95 30836 13503\n",
    "9.95 28637 11060\n",
    "10.95 26239 9032\n",
    "11.95 24636 7687\n",
    "12.95 22876 6432\n",
    "14.43 41267 9813\n",
    "16.43 35712 7196\n",
    "18.44 31573 5290\n",
    "20.44 28280 4086\n",
    "21.95 13238 1642\n",
    "24.39 46570 4767\n",
    "28.40 38422 2980\n",
    "32.39 31641 1996\n",
    "36.39 25604 1327\n",
    "40.37 20366 834\n",
    "44.38 15977 559\n",
    "48.37 11770 311\n",
    "52.36 8708 231\n",
    "57.25 8878 204\n",
    "63.23 5492 103\n",
    "69.18 3087 35\n",
    "75.19 1742 24\"\"\"\n",
    "\n",
    "new_golf_data = pd.read_csv(io.StringIO(new_golf_data), sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_golf_data(new_golf_data)\n",
    "plot_golf_data(golf_data, ax=ax, color=\"C1\")\n",
    "\n",
    "t_ary = np.linspace(CUP_RADIUS - BALL_RADIUS, new_golf_data.distance.max(), 200)\n",
    "t = xr.DataArray(t_ary, coords=[(\"distance\", t_ary)])\n",
    "\n",
    "ax.plot(\n",
    "    t, forward_angle_model(angle_trace.posterior[\"variance_of_shot\"], t).mean((\"chain\", \"draw\"))\n",
    ")\n",
    "ax.set_title(\"Comparing the new data set to the old data set, and\\nconsidering the old model fit\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new data set represents ~200 times the number of putt attempts as the old data, and includes putts up to 75ft, compared to 20ft for the old data set. It also seems that the new data represents a different population from the old data: while the two have different bins, the new data suggests higher success for most data. This may be from a different method of collecting the data, or golfers improving in the intervening years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model on the new data\n",
    "\n",
    "Since we think these may be two different populations, the easiest solution would be to refit our model. This goes worse than earlier: there are divergences, and it takes much longer to run. This may indicate a problem with the model: Andrew Gelman calls this the \"folk theorem of statistical computing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with angle_model:\n",
    "    pm.set_data(\n",
    "        {\n",
    "            \"distance\": new_golf_data[\"distance\"],\n",
    "            \"tries\": new_golf_data[\"tries\"],\n",
    "            \"successes\": new_golf_data[\"successes\"],\n",
    "        }\n",
    "    )\n",
    "    new_angle_trace = pm.sample(1000, tune=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "As you will see in the plot below, this model fits the new data quite badly. In this case, all the divergences\n",
    "and convergence warnings have no other solution than using a different model that can actually explain the data.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_golf_data(new_golf_data)\n",
    "plot_golf_data(golf_data, ax=ax, color=\"C1\")\n",
    "\n",
    "new_angle_post = az.extract(new_angle_trace)\n",
    "ax.plot(\n",
    "    t,\n",
    "    forward_angle_model(angle_post[\"variance_of_shot\"], t).mean(dim=\"sample\"),\n",
    "    label=\"Trained on original data\",\n",
    ")\n",
    "ax.plot(\n",
    "    t,\n",
    "    forward_angle_model(new_angle_post[\"variance_of_shot\"], t).mean(dim=\"sample\"),\n",
    "    label=\"Trained on new data\",\n",
    ")\n",
    "ax.set_title(\"Retraining the model on new data\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model incorporating distance to hole\n",
    "\n",
    "We might assume that, in addition to putting in the right direction, a golfer may need to hit the ball the right distance. Specifically, we assume:\n",
    "\n",
    "1. If a put goes short *or* more than 3 feet past the hole, it will not go in.\n",
    "2. Golfers aim for 1 foot past the hole\n",
    "3. The distance the ball goes, $u$, is distributed according to\n",
    "$$\n",
    "u \\sim \\mathcal{N}\\left(1 + \\text{distance}, \\sigma_{\\text{distance}} (1 + \\text{distance})\\right),\n",
    "$$\n",
    "where we will learn $\\sigma_{\\text{distance}}$.\n",
    "\n",
    "Again, this is a geometry and algebra problem to work the probability that the ball goes in from any given distance:\n",
    "$$\n",
    "P(\\text{good distance}) = P(\\text{distance} < u < \\text{distance} + 3)\n",
    "$$\n",
    "\n",
    "it uses `phi`, the cumulative normal density function we implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSHOT = 1.0\n",
    "DISTANCE_TOLERANCE = 3.0\n",
    "\n",
    "\n",
    "with pm.Model() as distance_angle_model:\n",
    "    distance_ = pm.MutableData(\"distance\", new_golf_data[\"distance\"], dims=\"obs_id\")\n",
    "    tries_ = pm.MutableData(\"tries\", new_golf_data[\"tries\"], dims=\"obs_id\")\n",
    "    successes_ = pm.MutableData(\"successes\", new_golf_data[\"successes\"], dims=\"obs_id\")\n",
    "\n",
    "    variance_of_shot = pm.HalfNormal(\"variance_of_shot\")\n",
    "    variance_of_distance = pm.HalfNormal(\"variance_of_distance\")\n",
    "    p_good_angle = pm.Deterministic(\n",
    "        \"p_good_angle\",\n",
    "        2 * phi(pt.arcsin((CUP_RADIUS - BALL_RADIUS) / distance_) / variance_of_shot) - 1,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "    p_good_distance = pm.Deterministic(\n",
    "        \"p_good_distance\",\n",
    "        phi((DISTANCE_TOLERANCE - OVERSHOT) / ((distance_ + OVERSHOT) * variance_of_distance))\n",
    "        - phi(-OVERSHOT / ((distance_ + OVERSHOT) * variance_of_distance)),\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "    success = pm.Binomial(\n",
    "        \"success\", n=tries_, p=p_good_angle * p_good_distance, observed=successes_, dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(distance_angle_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model still has only 2 dimensions to fit. We might think about checking on `OVERSHOT` and `DISTANCE_TOLERANCE`. Checking the first might involve a call to a local golf course, and the second might require a trip to a green and some time experimenting. We might also think about adding some explicit correlations: it is plausible that less control over angle would correspond to less control over distance, or that longer putts lead to more variance in the angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the distance angle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distance_angle_model:\n",
    "    distance_angle_trace = pm.sample(1000, tune=1000, target_accept=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_distance_angle_model(variance_of_shot, variance_of_distance, t):\n",
    "    rv = XrContinuousRV(st.norm, 0, 1)\n",
    "    angle_prob = 2 * rv.cdf(np.arcsin((CUP_RADIUS - BALL_RADIUS) / t) / variance_of_shot) - 1\n",
    "\n",
    "    distance_prob_one = rv.cdf(\n",
    "        (DISTANCE_TOLERANCE - OVERSHOT) / ((t + OVERSHOT) * variance_of_distance)\n",
    "    )\n",
    "    distance_prob_two = rv.cdf(-OVERSHOT / ((t + OVERSHOT) * variance_of_distance))\n",
    "    distance_prob = distance_prob_one - distance_prob_two\n",
    "\n",
    "    return angle_prob * distance_prob\n",
    "\n",
    "\n",
    "ax = plot_golf_data(new_golf_data)\n",
    "\n",
    "distance_angle_post = az.extract(distance_angle_trace)\n",
    "\n",
    "ax.plot(\n",
    "    t,\n",
    "    forward_angle_model(new_angle_post[\"variance_of_shot\"], t).mean(dim=\"sample\"),\n",
    "    label=\"Just angle\",\n",
    ")\n",
    "ax.plot(\n",
    "    t,\n",
    "    forward_distance_angle_model(\n",
    "        distance_angle_post[\"variance_of_shot\"],\n",
    "        distance_angle_post[\"variance_of_distance\"],\n",
    "        t,\n",
    "    ).mean(dim=\"sample\"),\n",
    "    label=\"Distance and angle\",\n",
    ")\n",
    "\n",
    "ax.set_title(\"Comparing fits of models on new data\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model looks better, and fit much more quickly with fewer sampling problems compared to the old model.There is some mismatch between 10 and 40 feet, but it seems generally good. We can come to this same conclusion by taking posterior predictive samples, and looking at the residuals. Here, we see that the fit is being driven by the first 4 bins, which contain ~40% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distance_angle_model:\n",
    "    pm.sample_posterior_predictive(distance_angle_trace, extend_inferencedata=True)\n",
    "\n",
    "const_data = distance_angle_trace.constant_data\n",
    "pp = distance_angle_trace.posterior_predictive\n",
    "residuals = 100 * ((const_data[\"successes\"] - pp[\"success\"]) / const_data[\"tries\"]).mean(\n",
    "    (\"chain\", \"draw\")\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(new_golf_data.distance, residuals, \"o-\")\n",
    "ax.axhline(y=0, linestyle=\"dashed\", linewidth=1)\n",
    "ax.set_xlabel(\"Distance from hole\")\n",
    "ax.set_ylabel(\"Absolute error in expected\\npercent of success\")\n",
    "\n",
    "ax.set_title(\"Residuals of new model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A new model\n",
    "\n",
    "It is reasonable to stop at this point, but if we want to improve the fit everywhere, we may want to choose a different likelihood from the `Binomial`, which cares deeply about those points with many observations. One thing we could do is add some independent extra error to each data point. We could do this in a few ways:\n",
    "1. The `Binomial` distribution in usually parametrized by $n$, the number of observations, and $p$, the probability of an individual success. We could instead parametrize it by mean ($np$) and variance ($np(1-p)$), and add error independent of $n$ to the likelihood.\n",
    "2. Use a `BetaBinomial` distribution, though the error there would still be (roughly) proportional to the number observations\n",
    "3. Approximate the Binomial with a Normal distribution of the probability of success. This is actually equivalent to the first approach, but does not require a custom distribution. Note that we will use $p$ as the mean, and $p(1-p) / n$ as the variance. Once we add some dispersion $\\epsilon$, the variance becomes $p(1-p)/n + \\epsilon$.\n",
    "\n",
    "We follow approach 3, as in the Stan case study, and leave 1 as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as disp_distance_angle_model:\n",
    "    distance_ = pm.MutableData(\"distance\", new_golf_data[\"distance\"], dims=\"obs_id\")\n",
    "    tries_ = pm.MutableData(\"tries\", new_golf_data[\"tries\"], dims=\"obs_id\")\n",
    "    successes_ = pm.MutableData(\"successes\", new_golf_data[\"successes\"], dims=\"obs_id\")\n",
    "    obs_prop_ = pm.MutableData(\n",
    "        \"obs_prop\", new_golf_data[\"successes\"] / new_golf_data[\"tries\"], dims=\"obs_id\"\n",
    "    )\n",
    "\n",
    "    variance_of_shot = pm.HalfNormal(\"variance_of_shot\")\n",
    "    variance_of_distance = pm.HalfNormal(\"variance_of_distance\")\n",
    "    dispersion = pm.HalfNormal(\"dispersion\")\n",
    "\n",
    "    p_good_angle = pm.Deterministic(\n",
    "        \"p_good_angle\",\n",
    "        2 * phi(pt.arcsin((CUP_RADIUS - BALL_RADIUS) / distance_) / variance_of_shot) - 1,\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "    p_good_distance = pm.Deterministic(\n",
    "        \"p_good_distance\",\n",
    "        phi((DISTANCE_TOLERANCE - OVERSHOT) / ((distance_ + OVERSHOT) * variance_of_distance))\n",
    "        - phi(-OVERSHOT / ((distance_ + OVERSHOT) * variance_of_distance)),\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "    p = p_good_angle * p_good_distance\n",
    "    p_success = pm.Normal(\n",
    "        \"p_success\",\n",
    "        mu=p,\n",
    "        sigma=pt.sqrt(((p * (1 - p)) / tries_) + dispersion**2),\n",
    "        observed=obs_prop_,  # successes_ / tries_\n",
    "        dims=\"obs_id\",\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(disp_distance_angle_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with disp_distance_angle_model:\n",
    "    disp_distance_angle_trace = pm.sample(1000, tune=1000)\n",
    "    pm.sample_posterior_predictive(disp_distance_angle_trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_golf_data(new_golf_data, ax=None)\n",
    "\n",
    "disp_distance_angle_post = az.extract(disp_distance_angle_trace)\n",
    "\n",
    "ax.plot(\n",
    "    t,\n",
    "    forward_distance_angle_model(\n",
    "        distance_angle_post[\"variance_of_shot\"],\n",
    "        distance_angle_post[\"variance_of_distance\"],\n",
    "        t,\n",
    "    ).mean(dim=\"sample\"),\n",
    "    label=\"Distance and angle\",\n",
    ")\n",
    "ax.plot(\n",
    "    t,\n",
    "    forward_distance_angle_model(\n",
    "        disp_distance_angle_post[\"variance_of_shot\"],\n",
    "        disp_distance_angle_post[\"variance_of_distance\"],\n",
    "        t,\n",
    "    ).mean(dim=\"sample\"),\n",
    "    label=\"Dispersed model\",\n",
    ")\n",
    "ax.set_title(\"Comparing dispersed model with binomial distance/angle model\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model does better between 10 and 30 feet, as we can also see using the residuals plot - note that this model does marginally worse for very short putts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_data = distance_angle_trace.constant_data\n",
    "old_pp = az.extract(distance_angle_trace, group=\"posterior_predictive\")\n",
    "old_residuals = 100 * ((const_data[\"successes\"] - old_pp[\"success\"]) / const_data[\"tries\"]).mean(\n",
    "    dim=\"sample\"\n",
    ")\n",
    "\n",
    "pp = az.extract(disp_distance_angle_trace, group=\"posterior_predictive\")\n",
    "residuals = 100 * (const_data[\"successes\"] / const_data[\"tries\"] - pp[\"p_success\"]).mean(\n",
    "    dim=\"sample\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(new_golf_data.distance, residuals, label=\"Dispersed model\")\n",
    "ax.plot(new_golf_data.distance, old_residuals, label=\"Distance and angle model\")\n",
    "ax.legend()\n",
    "ax.axhline(y=0, linestyle=\"dashed\", linewidth=1)\n",
    "ax.set_xlabel(\"Distance from hole\")\n",
    "ax.set_ylabel(\"Absolute error in expected\\npercent of success\")\n",
    "ax.set_title(\"Residuals of dispersed model vs distance/angle model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond prediction\n",
    "\n",
    "We want to use Bayesian analysis because we care about quantifying uncertainty in our parameters. We have a beautiful geometric model that not only gives us predictions, but gives us posterior distributions over our parameters. We can use this to back out how where our putts may end up, if not in the hole!\n",
    "\n",
    "First, we can try to visualize how 20,000 putts from a professional golfer might look. We:\n",
    "\n",
    "1. Set the number of trials to 5\n",
    "2. For each *joint* posterior sample of `variance_of_shot` and `variance_of_distance`,\n",
    "   draw an angle and a distance from normal distribution 5 times.\n",
    "3. Plot the point, unless it would have gone in the hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_from_distance(trace, distance_to_hole, trials=5):\n",
    "    variance_of_shot = trace.posterior[\"variance_of_shot\"]\n",
    "    variance_of_distance = trace.posterior[\"variance_of_distance\"]\n",
    "\n",
    "    theta = XrContinuousRV(st.norm, 0, variance_of_shot).rvs(size=trials, dims=\"trials\")\n",
    "    distance = XrContinuousRV(\n",
    "        st.norm, distance_to_hole + OVERSHOT, (distance_to_hole + OVERSHOT) * variance_of_distance\n",
    "    ).rvs(size=trials, dims=\"trials\")\n",
    "\n",
    "    final_position = xr.concat(\n",
    "        (distance * np.cos(theta), distance * np.sin(theta)), dim=\"axis\"\n",
    "    ).assign_coords(axis=[\"x\", \"y\"])\n",
    "\n",
    "    made_it = np.abs(theta) < np.arcsin((CUP_RADIUS - BALL_RADIUS) / distance_to_hole)\n",
    "    made_it = (\n",
    "        made_it\n",
    "        * (final_position.sel(axis=\"x\") > distance_to_hole)\n",
    "        * (final_position.sel(axis=\"x\") < distance_to_hole + DISTANCE_TOLERANCE)\n",
    "    )\n",
    "\n",
    "    dims = [dim for dim in final_position.dims if dim != \"axis\"]\n",
    "    final_position = final_position.where(~made_it).stack(idx=dims).dropna(dim=\"idx\")\n",
    "    total_simulations = made_it.size\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(0, 0, \"k.\", lw=1, mfc=\"black\", ms=250 / distance_to_hole)\n",
    "    ax.plot(*final_position, \".\", alpha=0.1, mfc=\"r\", ms=250 / distance_to_hole, mew=0.5)\n",
    "    ax.plot(distance_to_hole, 0, \"ko\", lw=1, mfc=\"black\", ms=350 / distance_to_hole)\n",
    "\n",
    "    ax.set_facecolor(\"#e6ffdb\")\n",
    "    ax.set_title(\n",
    "        f\"Final position of {total_simulations:,d} putts from {distance_to_hole}ft.\\n\"\n",
    "        f\"({100 * made_it.mean().item():.1f}% made)\"\n",
    "    )\n",
    "    return ax\n",
    "\n",
    "\n",
    "simulate_from_distance(distance_angle_trace, distance_to_hole=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_from_distance(distance_angle_trace, distance_to_hole=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this to work out how many putts a player may need to take from a given distance. This can influence strategic decisions like trying to reach the green in fewer shots, which may lead to a longer first putt, vs. a more conservative approach. We do this by simulating putts until they have all gone in.\n",
    "\n",
    "Note that this is again something we might check experimentally. In particular, a highly unscientific search around the internet finds claims that professionals only 3-putt from 20-25ft around 3% of the time. Our model puts the chance of 3 or more putts from 22.5 feet at 2.8%, which seems suspiciously good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_num_putts(trace, distance_to_hole, trials=100_000):\n",
    "    distance_to_hole = distance_to_hole * np.ones(trials)\n",
    "\n",
    "    combined_trace = az.extract(trace)\n",
    "\n",
    "    n_samples = combined_trace.dims[\"sample\"]\n",
    "\n",
    "    idxs = np.random.randint(0, n_samples, trials)\n",
    "    variance_of_shot = combined_trace[\"variance_of_shot\"].isel(sample=idxs)\n",
    "    variance_of_distance = combined_trace[\"variance_of_distance\"].isel(sample=idxs)\n",
    "    n_shots = []\n",
    "    while distance_to_hole.size > 0:\n",
    "        theta = np.random.normal(0, variance_of_shot)\n",
    "        distance = np.random.normal(\n",
    "            distance_to_hole + OVERSHOT, (distance_to_hole + OVERSHOT) * variance_of_distance\n",
    "        )\n",
    "\n",
    "        final_position = np.array([distance * np.cos(theta), distance * np.sin(theta)])\n",
    "\n",
    "        made_it = np.abs(theta) < np.arcsin(\n",
    "            (CUP_RADIUS - BALL_RADIUS) / distance_to_hole.clip(min=CUP_RADIUS - BALL_RADIUS)\n",
    "        )\n",
    "        made_it = (\n",
    "            made_it\n",
    "            * (final_position[0] > distance_to_hole)\n",
    "            * (final_position[0] < distance_to_hole + DISTANCE_TOLERANCE)\n",
    "        )\n",
    "\n",
    "        distance_to_hole = np.sqrt(\n",
    "            (final_position[0] - distance_to_hole) ** 2 + final_position[1] ** 2\n",
    "        )[~made_it].copy()\n",
    "        variance_of_shot = variance_of_shot[~made_it]\n",
    "        variance_of_distance = variance_of_distance[~made_it]\n",
    "        n_shots.append(made_it.sum())\n",
    "    return np.array(n_shots) / trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = (10, 20, 40, 80)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(10, 10))\n",
    "\n",
    "for distance, ax in zip(distances, axes.ravel()):\n",
    "    made = 100 * expected_num_putts(disp_distance_angle_trace, distance)\n",
    "    x = np.arange(1, 1 + len(made), dtype=int)\n",
    "    ax.vlines(np.arange(1, 1 + len(made)), 0, made, linewidths=50)\n",
    "    ax.set_title(f\"{distance} feet\")\n",
    "    ax.set_ylabel(\"Percent of attempts\")\n",
    "    ax.set_xlabel(\"Number of putts\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlim(0, 5.6)\n",
    "fig.suptitle(\"Simulated number of putts from\\na few distances\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "* Adapted by Colin Carroll from the [Model building and expansion for golf putting] case study in the Stan documentation ([pymc#3666](https://github.com/pymc-devs/pymc/pull/3666))\n",
    "* Updated by Marco Gorelli ([pymc-examples#39](https://github.com/pymc-devs/pymc-examples/pull/39))\n",
    "* Updated by Oriol Abril-Pla to use PyMC v4 and xarray-einstats\n",
    "* Updated by [Benjamin T. Vincent](https://github.com/drbenvincent) to use `az.extract` in February 2023 ([pymc-examples#522](https://github.com/pymc-devs/pymc-examples/pull/522))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    ":::{bibliography}\n",
    ":filter: docname in docnames\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p aeppl,xarray_einstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "087adf61916f8b9a562e3919cc7201fe0599d07c87f54bc57443476208d67f09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
