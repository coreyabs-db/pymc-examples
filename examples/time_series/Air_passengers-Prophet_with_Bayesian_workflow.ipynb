{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Air_passengers-Prophet_with_Bayesian_workflow)=\n",
    "# Air passengers - Prophet-like model\n",
    "\n",
    ":::{post} April, 2022\n",
    ":tags: time series, prophet \n",
    ":category: intermediate\n",
    ":author: Marco Gorelli, Danh Phan\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to look at the \"air passengers\" dataset, which tracks the monthly totals of a US airline passengers from 1949 to 1960. We could fit this using the [Prophet](https://facebook.github.io/prophet/) model {cite:p}`taylor2018forecasting` (indeed, this dataset is one of the examples they provide in their documentation), but instead we'll make our own Prophet-like model in PyMC3. This will make it a lot easier to inspect the model's components and to do prior predictive checks (an integral component of the [Bayesian workflow](https://arxiv.org/abs/2011.01808) {cite:p}`gelman2020bayesian`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "try:\n",
    "    df = pd.read_csv(\"../data/AirPassengers.csv\", parse_dates=[\"Month\"])\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv(pm.get_data(\"AirPassengers.csv\"), parse_dates=[\"Month\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we begin: visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an increasing trend, with multiplicative seasonality. We'll fit a linear trend, and \"borrow\" the multiplicative seasonality part of it from Prophet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll scale time to be between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (df[\"Month\"] - pd.Timestamp(\"1900-01-01\")).dt.days.to_numpy()\n",
    "t_min = np.min(t)\n",
    "t_max = np.max(t)\n",
    "t = (t - t_min) / (t_max - t_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for the target variable, we divide by the maximum. We do this, rather than standardising, so that the sign of the observations in unchanged - this will be necessary for the seasonality component to work properly later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"#Passengers\"].to_numpy()\n",
    "y_max = np.max(y)\n",
    "y = y / y_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: linear trend\n",
    "\n",
    "The model we'll fit, for now, will just be\n",
    "\n",
    "$$\\text{Passengers} \\sim \\alpha + \\beta\\ \\text{time}$$\n",
    "\n",
    "First, let's try using the default priors set by prophet, and we'll do a prior predictive check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(check_bounds=False) as linear:\n",
    "    α = pm.Normal(\"α\", mu=0, sigma=5)\n",
    "    β = pm.Normal(\"β\", mu=0, sigma=5)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=5)\n",
    "    trend = pm.Deterministic(\"trend\", α + β * t)\n",
    "    pm.Normal(\"likelihood\", mu=trend, sigma=σ, observed=y)\n",
    "\n",
    "    linear_prior = pm.sample_prior_predictive()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "ax[0].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_prior, group=\"prior_predictive\", num_samples=100)[\"likelihood\"]\n",
    "    * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[0])\n",
    "ax[0].set_title(\"Prior predictive\")\n",
    "ax[1].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_prior, group=\"prior\", num_samples=100)[\"trend\"] * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[1])\n",
    "ax[1].set_title(\"Prior trend lines\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better than this. These priors are evidently too wide, as we end up with implausibly many passengers. Let's try setting tighter priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(check_bounds=False) as linear:\n",
    "    α = pm.Normal(\"α\", mu=0, sigma=0.5)\n",
    "    β = pm.Normal(\"β\", mu=0, sigma=0.5)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=0.1)\n",
    "    trend = pm.Deterministic(\"trend\", α + β * t)\n",
    "    pm.Normal(\"likelihood\", mu=trend, sigma=σ, observed=y)\n",
    "\n",
    "    linear_prior = pm.sample_prior_predictive(samples=100)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "ax[0].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_prior, group=\"prior_predictive\", num_samples=100)[\"likelihood\"]\n",
    "    * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[0])\n",
    "ax[0].set_title(\"Prior predictive\")\n",
    "ax[1].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_prior, group=\"prior\", num_samples=100)[\"trend\"] * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[1])\n",
    "ax[1].set_title(\"Prior trend lines\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Before going on to anything more complicated, let's try conditioning on the data and doing a posterior predictive check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with linear:\n",
    "    linear_trace = pm.sample(return_inferencedata=True)\n",
    "    linear_prior = pm.sample_posterior_predictive(trace=linear_trace)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "ax[0].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_prior, group=\"posterior_predictive\", num_samples=100)[\"likelihood\"]\n",
    "    * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.01,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[0])\n",
    "ax[0].set_title(\"Posterior predictive\")\n",
    "ax[1].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_trace, group=\"posterior\", num_samples=100)[\"trend\"] * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.01,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[1])\n",
    "ax[1].set_title(\"Posterior trend lines\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: enter seasonality\n",
    "\n",
    "To model seasonality, we'll \"borrow\" the approach taken by Prophet - see [the Prophet paper](https://peerj.com/preprints/3190/) {cite:p}`taylor2018forecasting` for details, but the idea is to make a matrix of Fourier features which get multiplied by a vector of coefficients. As we'll be using multiplicative seasonality, the final model will be\n",
    "\n",
    "$$\\text{Passengers} \\sim (\\alpha + \\beta\\ \\text{time}) (1 + \\text{seasonality})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_order = 10\n",
    "periods = (df[\"Month\"] - pd.Timestamp(\"1900-01-01\")).dt.days / 365.25\n",
    "\n",
    "fourier_features = pd.DataFrame(\n",
    "    {\n",
    "        f\"{func}_order_{order}\": getattr(np, func)(2 * np.pi * periods * order)\n",
    "        for order in range(1, n_order + 1)\n",
    "        for func in (\"sin\", \"cos\")\n",
    "    }\n",
    ")\n",
    "fourier_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's use the default Prophet priors, just to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"fourier_features\": np.arange(2 * n_order)}\n",
    "with pm.Model(check_bounds=False, coords=coords) as linear_with_seasonality:\n",
    "    α = pm.Normal(\"α\", mu=0, sigma=0.5)\n",
    "    β = pm.Normal(\"β\", mu=0, sigma=0.5)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=0.1)\n",
    "    β_fourier = pm.Normal(\"β_fourier\", mu=0, sigma=10, dims=\"fourier_features\")\n",
    "    seasonality = pm.Deterministic(\n",
    "        \"seasonality\", pm.math.dot(β_fourier, fourier_features.to_numpy().T)\n",
    "    )\n",
    "    trend = pm.Deterministic(\"trend\", α + β * t)\n",
    "    μ = trend * (1 + seasonality)\n",
    "    pm.Normal(\"likelihood\", mu=μ, sigma=σ, observed=y)\n",
    "\n",
    "    linear_seasonality_prior = pm.sample_prior_predictive()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=1, sharex=False, figsize=(8, 6))\n",
    "ax[0].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_seasonality_prior, group=\"prior_predictive\", num_samples=100)[\n",
    "        \"likelihood\"\n",
    "    ]\n",
    "    * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[0])\n",
    "ax[0].set_title(\"Prior predictive\")\n",
    "ax[1].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_seasonality_prior, group=\"prior\", num_samples=100)[\"trend\"] * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[1])\n",
    "ax[1].set_title(\"Prior trend lines\")\n",
    "ax[2].plot(\n",
    "    df[\"Month\"].iloc[:12],\n",
    "    az.extract_dataset(linear_seasonality_prior, group=\"prior\", num_samples=100)[\"seasonality\"][:12]\n",
    "    * 100,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "ax[2].set_title(\"Prior seasonality\")\n",
    "ax[2].set_ylabel(\"Percent change\")\n",
    "formatter = mdates.DateFormatter(\"%b\")\n",
    "ax[2].xaxis.set_major_formatter(formatter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this seems implausible. The default priors are too wide for our use-case, and it doesn't make sense to use them when we can do prior predictive checks to set more sensible ones. Let's try with some narrower ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"fourier_features\": np.arange(2 * n_order)}\n",
    "with pm.Model(check_bounds=False, coords=coords) as linear_with_seasonality:\n",
    "    α = pm.Normal(\"α\", mu=0, sigma=0.5)\n",
    "    β = pm.Normal(\"β\", mu=0, sigma=0.5)\n",
    "    trend = pm.Deterministic(\"trend\", α + β * t)\n",
    "\n",
    "    β_fourier = pm.Normal(\"β_fourier\", mu=0, sigma=0.1, dims=\"fourier_features\")\n",
    "    seasonality = pm.Deterministic(\n",
    "        \"seasonality\", pm.math.dot(β_fourier, fourier_features.to_numpy().T)\n",
    "    )\n",
    "\n",
    "    μ = trend * (1 + seasonality)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=0.1)\n",
    "    pm.Normal(\"likelihood\", mu=μ, sigma=σ, observed=y)\n",
    "\n",
    "    linear_seasonality_prior = pm.sample_prior_predictive()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=1, sharex=False, figsize=(8, 6))\n",
    "ax[0].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_seasonality_prior, group=\"prior_predictive\", num_samples=100)[\n",
    "        \"likelihood\"\n",
    "    ]\n",
    "    * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[0])\n",
    "ax[0].set_title(\"Prior predictive\")\n",
    "ax[1].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_seasonality_prior, group=\"prior\", num_samples=100)[\"trend\"] * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[1])\n",
    "ax[1].set_title(\"Prior trend lines\")\n",
    "ax[2].plot(\n",
    "    df[\"Month\"].iloc[:12],\n",
    "    az.extract_dataset(linear_seasonality_prior, group=\"prior\", num_samples=100)[\"seasonality\"][:12]\n",
    "    * 100,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "ax[2].set_title(\"Prior seasonality\")\n",
    "ax[2].set_ylabel(\"Percent change\")\n",
    "formatter = mdates.DateFormatter(\"%b\")\n",
    "ax[2].xaxis.set_major_formatter(formatter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems a lot more believable. Time for a posterior predictive check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with linear_with_seasonality:\n",
    "    linear_seasonality_trace = pm.sample(return_inferencedata=True)\n",
    "    linear_seasonality_posterior = pm.sample_posterior_predictive(trace=linear_seasonality_trace)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=1, sharex=False, figsize=(8, 6))\n",
    "ax[0].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_seasonality_posterior, group=\"posterior_predictive\", num_samples=100)[\n",
    "        \"likelihood\"\n",
    "    ]\n",
    "    * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[0])\n",
    "ax[0].set_title(\"Posterior predictive\")\n",
    "ax[1].plot(\n",
    "    df[\"Month\"],\n",
    "    az.extract_dataset(linear_trace, group=\"posterior\", num_samples=100)[\"trend\"] * y_max,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "df.plot.scatter(x=\"Month\", y=\"#Passengers\", color=\"k\", ax=ax[1])\n",
    "ax[1].set_title(\"Posterior trend lines\")\n",
    "ax[2].plot(\n",
    "    df[\"Month\"].iloc[:12],\n",
    "    az.extract_dataset(linear_seasonality_trace, group=\"posterior\", num_samples=100)[\"seasonality\"][\n",
    "        :12\n",
    "    ]\n",
    "    * 100,\n",
    "    color=\"blue\",\n",
    "    alpha=0.05,\n",
    ")\n",
    "ax[2].set_title(\"Posterior seasonality\")\n",
    "ax[2].set_ylabel(\"Percent change\")\n",
    "formatter = mdates.DateFormatter(\"%b\")\n",
    "ax[2].xaxis.set_major_formatter(formatter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We saw how we could implement a Prophet-like model ourselves and fit it to the air passengers dataset. Prophet is an awesome library and a net-positive to the community, but by implementing it ourselves, however, we can take whichever components of it we think are relevant to our problem, customise them, and carry out the Bayesian workflow {cite:p}`gelman2020bayesian`). Next time you have a time series problem, I hope you will try implementing your own probabilistic model rather than using Prophet as a \"black-box\" whose arguments are tuneable hyperparameters.\n",
    "\n",
    "For reference, you might also want to check out:\n",
    "- [TimeSeeers](https://github.com/MBrouns/timeseers), a hierarchical Bayesian Time Series model based on Facebooks Prophet, written in PyMC3\n",
    "- [PM-Prophet](https://github.com/luke14free/pm-prophet), a Pymc3-based universal time series prediction and decomposition library inspired by Facebook Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "* Authored by [Marco Gorelli](https://github.com/MarcoGorelli) in June, 2021 ([pymc-examples#183](https://github.com/pymc-devs/pymc-examples/pull/183))\n",
    "* Updated by Danh Phan in May, 2022 ([pymc-examples#320](https://github.com/pymc-devs/pymc-examples/pull/320))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    ":::{bibliography}\n",
    ":filter: docname in docnames\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p pytensor,aeppl,xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
