{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(AR)=\n",
    "# Analysis of An $AR(1)$ Model in PyMC\n",
    ":::{post} Jan 7, 2023\n",
    ":tags: time series, autoregressive \n",
    ":category: intermediate,\n",
    ":author: Ed Herbst, Chris Fonnesbeck\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Consider the following AR(2) process, initialized in the\n",
    "infinite past:\n",
    "$$\n",
    "   y_t = \\rho_0 + \\rho_1 y_{t-1} + \\rho_2 y_{t-2} + \\epsilon_t,\n",
    "$$\n",
    "where $\\epsilon_t \\overset{iid}{\\sim} {\\cal N}(0,1)$.  Suppose you'd like to learn about $\\rho$ from a a sample of observations $Y^T = \\{ y_0, y_1,\\ldots, y_T \\}$.\n",
    "\n",
    "First, let's generate some synthetic sample data. We simulate the 'infinite past' by generating 10,000 samples from an AR(2) process and then discarding the first 5,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "T = 10000\n",
    "\n",
    "# true stationarity:\n",
    "true_rho = 0.7, -0.3\n",
    "# true standard deviation of the innovation:\n",
    "true_sigma = 2.0\n",
    "# true process mean:\n",
    "true_center = -1.0\n",
    "\n",
    "y = np.random.normal(loc=true_center, scale=true_sigma, size=T)\n",
    "y[1] += true_rho[0] * y[0]\n",
    "for t in range(2, T - 100):\n",
    "    y[t] += true_rho[0] * y[t - 1] + true_rho[1] * y[t - 2]\n",
    "\n",
    "y = y[-5000:]\n",
    "plt.plot(y, alpha=0.8)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"$y$\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's start by trying to fit the wrong model! Assume that we do no know the generative model and so simply fit an AR(1) model for simplicity.\n",
    "\n",
    "This generative process is quite straight forward to implement in PyMC. Since we wish to include an intercept term in the AR process, we must set `constant=True` otherwise PyMC will assume that we want an AR2 process when `rho` is of size 2. Also, by default a $N(0, 100)$ distribution will be used as the prior for the initial value. We can override this by passing a distribution (not a full RV) to the `init_dist` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as ar1:\n",
    "    # assumes 95% of prob mass is between -2 and 2\n",
    "    rho = pm.Normal(\"rho\", mu=0.0, sigma=1.0, shape=2)\n",
    "    # precision of the innovation term\n",
    "    tau = pm.Exponential(\"tau\", lam=0.5)\n",
    "\n",
    "    likelihood = pm.AR(\n",
    "        \"y\", rho=rho, tau=tau, constant=True, init_dist=pm.Normal.dist(0, 10), observed=y\n",
    "    )\n",
    "\n",
    "    idata = pm.sample(1000, tune=2000, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even though we assumed the wrong model, the parameter estimates are actually not that far from the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    idata,\n",
    "    lines=[\n",
    "        (\"rho\", {}, [true_center, true_rho[0]]),\n",
    "        (\"tau\", {}, true_sigma**-2),\n",
    "    ],\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Extension to AR(p)\n",
    "Now let's fit the correct underlying model, an AR(2):\n",
    "\n",
    "$$\n",
    " y_t = \\rho_0 + \\rho_1 y_{t-1} + \\rho_2 y_{t-2} + \\epsilon_t.\n",
    "$$\n",
    "\n",
    "The `AR` distribution infers the order of the process thanks to the size the of `rho` argmument passed to `AR` (including the mean). \n",
    "\n",
    "We will also use the standard deviation of the innovations (rather than the precision) to parameterize the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as ar2:\n",
    "    rho = pm.Normal(\"rho\", 0.0, 1.0, shape=3)\n",
    "    sigma = pm.HalfNormal(\"sigma\", 3)\n",
    "    likelihood = pm.AR(\n",
    "        \"y\", rho=rho, sigma=sigma, constant=True, init_dist=pm.Normal.dist(0, 10), observed=y\n",
    "    )\n",
    "\n",
    "    idata = pm.sample(\n",
    "        1000,\n",
    "        tune=2000,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior plots show that we have correctly inferred the generative model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    idata,\n",
    "    lines=[\n",
    "        (\"rho\", {}, (true_center,) + true_rho),\n",
    "        (\"sigma\", {}, true_sigma),\n",
    "    ],\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You can also pass the set of AR parameters as a list, if they are not identically distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pytensor.tensor as pt\n",
    "\n",
    "with pm.Model() as ar2_bis:\n",
    "    rho0 = pm.Normal(\"rho0\", mu=0.0, sigma=5.0)\n",
    "    rho1 = pm.Uniform(\"rho1\", -1, 1)\n",
    "    rho2 = pm.Uniform(\"rho2\", -1, 1)\n",
    "    sigma = pm.HalfNormal(\"sigma\", 3)\n",
    "    likelihood = pm.AR(\n",
    "        \"y\",\n",
    "        rho=pt.stack([rho0, rho1, rho2]),\n",
    "        sigma=sigma,\n",
    "        constant=True,\n",
    "        init_dist=pm.Normal.dist(0, 10),\n",
    "        observed=y,\n",
    "    )\n",
    "\n",
    "    idata = pm.sample(\n",
    "        1000,\n",
    "        tune=2000,\n",
    "        target_accept=0.9,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    idata,\n",
    "    lines=[\n",
    "        (\"rho0\", {}, true_center),\n",
    "        (\"rho1\", {}, true_rho[0]),\n",
    "        (\"rho2\", {}, true_rho[1]),\n",
    "        (\"sigma\", {}, true_sigma),\n",
    "    ],\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "* authored by Ed Herbst in August, 2016 ([pymc#1546](https://github.com/pymc-devs/pymc/pull/2285))\n",
    "* updated Chris Fonnesbeck in January, 2023 ([pymc-examples#493](https://github.com/pymc-devs/pymc-examples/pull/494))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p pytensor,aeppl,xarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 | packaged by conda-forge | (default, Nov 26 2020, 07:57:39) \n[GCC 9.3.0]"
  },
  "name": "AR.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "d54ac2181a459dda88915244fad851391a089975b391e6a024564737e40ca82a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
