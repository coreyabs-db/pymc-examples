{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The prevalence of malaria in the Gambia)=\n",
    "# The prevalence of malaria in the Gambia\n",
    "\n",
    ":::{post} Aug 24, 2024 \n",
    ":tags: spatial, autoregressive, count data\n",
    ":category: beginner, tutorial\n",
    ":author: Jonathan Dekermanjian\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../extra_installs.md\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dependencies need to be installed separately from PyMC\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import mapclassify\n",
    "import rasterio as rio\n",
    "\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we find ourselves with a sample of continuous measurements that are spatially related (Geostatistical data) and our goal is to determine an estimate of that measure in unsampled surrounding areas. In the following case-study we look at the number of individuals who test positive for malaria in our sample of 65 villages across the Gambia region and proceed with estimating the prevalence (total positive / total individuals tested) of malaria within the surrounding areas to the 65 sampled villages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tabular data\n",
    "try:\n",
    "    gambia = pd.read_csv(\"../data/gambia_dataset.csv\")\n",
    "except FileNotFoundError:\n",
    "    gambia = pd.read_csv(pm.get_data(\"gambia_dataset.csv\"))\n",
    "gambia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are currently on the individual person level but for our purposes we need it to be on the village level. We will aggregate the data by village to compute the total number of people tested, the number of people who tested positive, and the sample prevalence; which will be computed by dividing the total tested positive by the total tested individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each village compute the total tested, total positive, and the prevalence\n",
    "gambia_agg = (\n",
    "    gambia.groupby([\"x\", \"y\"])\n",
    "    .agg(total=(\"x\", \"size\"), positive=(\"pos\", \"sum\"))\n",
    "    .eval(\"prev = positive / total\")\n",
    "    .reset_index()\n",
    ")\n",
    "gambia_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert our dataframe into a geodataframe. In order to do this we need to know what coordinate reference system (CRS) either geographic coordinate system (GCS) or projected coordinate system (PCS) to use. GCS tells you where your data is on the earth, whereas PCS tells you how to draw your data on a two-dimensional plane. There are many different GCS/PCS because each GCS/PCS is a model of the earth's surface. However, the earth's surface is variable from one location to another. Therefore, different GCS/PCS versions will be more accurate depending on the geography your analysis is based in. Since our analysis is in the Gambia we will use PCS [EPSG 32628](https://epsg.io/32628) and GCS [EPSG 4326](https://epsg.io/4326) when plotting on a globe. Where EPSG stands for European Petroluem Survey Group, which is an organization that maintains geodetic parameters for coordinate systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataframe and set coordinate reference system to EPSG 4326\n",
    "gambia_gpdf = gpd.GeoDataFrame(\n",
    "    gambia_agg, geometry=gpd.points_from_xy(gambia_agg[\"x\"], gambia_agg[\"y\"]), crs=\"EPSG:32628\"\n",
    ").drop([\"x\", \"y\"], axis=1)\n",
    "\n",
    "gambia_gpdf_4326 = gambia_gpdf.to_crs(crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an interactive plot of the data with a cmap on the prevalence values\n",
    "gambia_gpdf_4326.round(2).explore(column=\"prev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to include on our map the elevations within the Gambia. To do that we extract the elevation values store in our raster file and overlay it on the map. Areas with darker red signify higher elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the raster image of elevations in the Gambia on top of the map\n",
    "m = gambia_gpdf_4326.round(2).explore(column=\"prev\")\n",
    "\n",
    "## Load the elevation rasterfile\n",
    "in_path = \"../data/GMB_elv_msk.tif\"\n",
    "\n",
    "dst_crs = \"EPSG:4326\"\n",
    "\n",
    "with rio.open(in_path) as src:\n",
    "\n",
    "    img = src.read()\n",
    "\n",
    "    src_crs = src.crs[\"init\"].upper()\n",
    "    min_lon, min_lat, max_lon, max_lat = src.bounds\n",
    "    xs = gambia_gpdf_4326[\"geometry\"].x\n",
    "    ys = gambia_gpdf_4326[\"geometry\"].y\n",
    "    rows, cols = rio.transform.rowcol(src.transform, xs, ys)\n",
    "\n",
    "## Conversion of elevation locations from UTM to WGS84 CRS\n",
    "bounds_orig = [[min_lat, min_lon], [max_lat, max_lon]]\n",
    "\n",
    "bounds_fin = []\n",
    "\n",
    "for item in bounds_orig:\n",
    "    # converting to lat/lon\n",
    "    lat = item[0]\n",
    "    lon = item[1]\n",
    "\n",
    "    proj = Transformer.from_crs(\n",
    "        int(src_crs.split(\":\")[1]), int(dst_crs.split(\":\")[1]), always_xy=True\n",
    "    )\n",
    "\n",
    "    lon_n, lat_n = proj.transform(lon, lat)\n",
    "\n",
    "    bounds_fin.append([lat_n, lon_n])\n",
    "\n",
    "# Finding the center of latitude & longitude\n",
    "centre_lon = bounds_fin[0][1] + (bounds_fin[1][1] - bounds_fin[0][1]) / 2\n",
    "centre_lat = bounds_fin[0][0] + (bounds_fin[1][0] - bounds_fin[0][0]) / 2\n",
    "\n",
    "# Overlay raster\n",
    "m.add_child(\n",
    "    folium.raster_layers.ImageOverlay(\n",
    "        img.transpose(1, 2, 0),\n",
    "        opacity=0.7,\n",
    "        bounds=bounds_fin,\n",
    "        overlay=True,\n",
    "        control=True,\n",
    "        cross_origin=False,\n",
    "        zindex=1,\n",
    "        colormap=lambda x: (1, 0, 0, x),\n",
    "    )\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to include elevation as a covariate in our model. So, we need to extract the values from the raster image and store it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the elevation values from the raster file and put them into a dataframe\n",
    "path = \"../data/GMB_elv_msk.tif\"\n",
    "\n",
    "with rio.open(path) as f:\n",
    "    arr = f.read(1)\n",
    "    mask = arr != f.nodata\n",
    "    elev = arr[mask]\n",
    "    col, row = np.where(mask)\n",
    "    x, y = f.xy(col, row)\n",
    "    uid = np.arange(f.height * f.width).reshape((f.height, f.width))[mask]\n",
    "\n",
    "result = np.rec.fromarrays([uid, x, y, elev], names=[\"id\", \"x\", \"y\", \"elev\"])\n",
    "elevations = pd.DataFrame(result)\n",
    "elevations = gpd.GeoDataFrame(\n",
    "    elevations, geometry=gpd.points_from_xy(elevations[\"x\"], elevations[\"y\"], crs=\"EPSG:4326\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the elevation values we need to perform a spatial join to our aggregated dataset with the prevalences. A spatial join is a special join that joins data based on geographical information. It is critical that when you perform such a join you use a projected coordinate system that is accurate for your geography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set coordinate system to EPSG 32628 and spatially join our prevalence dataframe to our elevations dataframe\n",
    "elevations = elevations.to_crs(epsg=\"32628\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gambia_gpdf = gambia_gpdf.sjoin_nearest(elevations, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CRS to EPSG 4326 for plotting\n",
    "gambia_gpdf_4326 = gambia_gpdf.to_crs(crs=\"EPSG:4326\")\n",
    "gambia_gpdf_4326.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant measures for modeling\n",
    "elev = gambia_gpdf[\"elev\"].values\n",
    "pos = gambia_gpdf[\"positive\"].values\n",
    "n = gambia_gpdf[\"total\"].values\n",
    "lonlat = gambia_gpdf[[\"y\", \"x\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize elevation values\n",
    "elev_std = (elev - np.mean(elev)) / np.std(elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility of results\n",
    "seed: int = sum(map(ord, \"spatialmalaria\"))\n",
    "rng: np.random.Generator = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the following model:\n",
    "$$Y_{i} \\sim Binomial(n_{i}, P(x_{i}))$$\n",
    "$$logit(P(x_{i})) = \\beta_{0} + \\beta_{1} \\times Elevation + S(x_{i})$$\n",
    "\n",
    "Where $n_{i}$ represents an individual tested for malaria, $P(x_{i})$ is the prevalence of malaria at location $x_{i}$, $\\beta_{0}$ is the intercept, $\\beta_{1}$ is the coefficient for the elevation covariate and $S(x_{i})$ is a zero mean field guassian process with a Matérn covariance function with $\\nu=\\frac{3}{2}$ that we will approximate using a Hilbert Space Gaussian Process (HSGP)\n",
    "\n",
    "In order to approximate a Gaussian process using an HSGP we need to select the parameters `m` and `c`. To learn more about how to set these parameters please refer to this wonderful ([example](../gaussian_processes/HSGP-Basic.myst.md)) of how to set these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as hsgp_model:\n",
    "    _X = pm.Data(\"X\", lonlat)\n",
    "    _elev = pm.Data(\"elevation\", elev_std)\n",
    "\n",
    "    ls = pm.Gamma(\"ls\", mu=20, sigma=5)\n",
    "    cov_func = pm.gp.cov.Matern32(2, ls=ls)\n",
    "    m0, m1, c = 40, 40, 2.5\n",
    "    gp = pm.gp.HSGP(m=[m0, m1], c=c, cov_func=cov_func)\n",
    "    s = gp.prior(\"s\", X=_X)\n",
    "\n",
    "    beta_0 = pm.Normal(\"beta_0\", 0, 1)\n",
    "    beta_1 = pm.Normal(\"beta_1\", 0, 1)\n",
    "\n",
    "    p_logit = pm.Deterministic(\"p_logit\", beta_0 + beta_1 * _elev + s)\n",
    "    p = pm.Deterministic(\"p\", pm.math.invlogit(p_logit))\n",
    "    pm.Binomial(\"likelihood\", n=n, logit_p=p_logit, observed=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsgp_model.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hsgp_model:\n",
    "    hsgp_trace = pm.sample(\n",
    "        1000, tune=2000, target_accept=0.95, nuts_sampler=\"numpyro\", random_seed=rng\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The posterior mean of the length scale is 0.21 (shown below). Therefore, we can expect the gaussian mean to decay towards 0 (since we set a 0 mean function) as we move 0.21 degrees away from any sampled point on the map. While this is not a hard cut-off due to the lengthscale not being constrained by the observed data it is still useful to be able to intuit how the lengthscale effects the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(hsgp_trace, var_names=[\"ls\"], kind=\"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Predictive Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to validate that our model specification properly represents the observed data. We can push out posterior predictions of the prevalence and plot them on a coordinate system to check if they resemble the observed prevalence from our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hsgp_model:\n",
    "    ppc = pm.sample_posterior_predictive(hsgp_trace, random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_prevalence = hsgp_trace[\"posterior\"][\"p\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that our posterior predictions in the figure below on the left agree with the observed sample shown on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.scatter(\n",
    "    lonlat[:, 1],\n",
    "    lonlat[:, 0],\n",
    "    c=posterior_prevalence.mean((\"chain\", \"draw\")),\n",
    "    marker=\"o\",\n",
    "    alpha=0.75,\n",
    "    s=100,\n",
    "    edgecolor=None,\n",
    ")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.title(\"Estimated Prevalence of Malaria in the Gambia\")\n",
    "plt.colorbar(label=\"Posterior mean\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.scatter(\n",
    "    lonlat[:, 1],\n",
    "    lonlat[:, 0],\n",
    "    c=gambia_gpdf_4326[\"prev\"],\n",
    "    marker=\"o\",\n",
    "    alpha=0.75,\n",
    "    s=100,\n",
    "    edgecolor=None,\n",
    ")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.title(\"Measured Sample Prevalence of Malaria in the Gambia\")\n",
    "plt.colorbar(label=\"Sample Prevalence\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if the likelihood (number of individuals who test positive for malaria) agrees with the observed data. As you can see in the below figure, our posterior predictive sample is representative of the observed sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(ppc, kind=\"cumulative\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-sample posterior predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have validated that we have a representative model that converged, we want to estimate the prevalence of malaria in the surrounding areas to where we have observed data points. Our new dataset will include every longitude and latitude position within the Gambia where we have a measure of elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new values for out-of-sample predictions\n",
    "new_lonlat = elevations[[\"y\", \"x\"]].to_numpy()\n",
    "new_elev = elevations[\"elev\"].to_numpy()\n",
    "new_elev_std = (new_elev - np.mean(new_elev)) / np.std(new_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hsgp_model:\n",
    "    pm.set_data(new_data={\"X\": new_lonlat, \"elevation\": new_elev_std})\n",
    "    pp = pm.sample_posterior_predictive(hsgp_trace, var_names=[\"p\"], random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_predictive_prevalence = pp[\"posterior_predictive\"][\"p\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our out-of-sample posterior predictions to visualize the estimated prevalence of malaria across the Gambia. In figure below you'll notice that there is a smooth transition of prevalences surrounding the areas where we observed data in a way where nearer areas have more similar prevalences and as you move away you approach zero (the mean of the guassian process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.scatter(\n",
    "    new_lonlat[:, 1],\n",
    "    new_lonlat[:, 0],\n",
    "    c=posterior_predictive_prevalence.mean((\"chain\", \"draw\")),\n",
    "    marker=\"o\",\n",
    "    alpha=0.75,\n",
    "    s=100,\n",
    "    edgecolor=None,\n",
    ")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.title(\"Prevalence of Malaria in the Gambia\")\n",
    "plt.colorbar(label=\"Posterior mean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making decisions based on exceedance probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to determine where we might decide to apply interventions is to look at exceedance probabilities of some selected threshold of malaria prevalence. These exeedance probabilities will allow us to incorporate our uncertainty in the prevalences we have estimated instead of just considering the mean of the posterior distribution. For our use case, we decide to set an exceedance threshold of 20% on the prevalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_prev_gt_20percent = 1 - (posterior_predictive_prevalence <= 0.2).mean((\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the insights gained from the figure below to send out aid to the regions where we are most confident that the prevalence of malaria exceeds 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.scatter(\n",
    "    new_lonlat[:, 1],\n",
    "    new_lonlat[:, 0],\n",
    "    c=prob_prev_gt_20percent,\n",
    "    marker=\"o\",\n",
    "    alpha=0.75,\n",
    "    s=100,\n",
    "    edgecolor=None,\n",
    ")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.title(\"Probability of Malaria Prevelance greater than 20%\")\n",
    "plt.colorbar(label=\"Posterior mean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Covariance Functions\n",
    "Before we conclude let's talk breifly about why we decided to use the Matérn family of covariance functions instead of the Exponential Quadratic. The Matérn family of covariances is a generalization of the Exponential Quadratic. When the smoothing parameter of the Matérn $\\nu \\to \\infty$ then we have the Exponential Quadratic covariance function. As the smoothing parameter increases the function you are estimating becomes smoother. A few commonly used values for $\\nu$ are $\\frac{1}{2}$, $\\frac{3}{2}$, and $\\frac{5}{2}$. Typically, when estimating a measure that has a spatial dependence we don't want an overly smooth function because that will prevent our estimate to capture abrupt changes in the measurement we are estimating. Below we simulate some data to show how the Matérn is able to capture these abrupt changes, whereas the Exponential Quadratic is overly smooth. For simplicity's sake we will be working in one dimension but these concepts apply with two-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate 1-dimensional data\n",
    "x = np.linspace(0, 10, 30)\n",
    "y = list()\n",
    "for v in x:\n",
    "    # introduce abrupt changes\n",
    "    if v > 3 and v < 7:\n",
    "        y.append(np.array(10.0))\n",
    "    else:\n",
    "        y.append(np.array(3.0))\n",
    "y = np.array(y).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GP to model the simulated data\n",
    "with pm.Model() as matern_model:\n",
    "\n",
    "    eta = pm.Exponential(\"eta\", scale=10.0)\n",
    "    ls = pm.Lognormal(\"ls\", mu=0.5, sigma=0.75)\n",
    "    cov_func = eta**2 * pm.gp.cov.Matern32(input_dim=1, ls=ls)\n",
    "    gp = pm.gp.Latent(cov_func=cov_func)\n",
    "    s = gp.prior(\"s\", X=x[:, None])\n",
    "\n",
    "    measurement_error = pm.Exponential(\"measurement_error\", scale=5.0)\n",
    "    pm.Normal(\"likelihood\", mu=s, sigma=measurement_error, observed=y)\n",
    "    matern_idata = pm.sample(\n",
    "        draws=2000, tune=2000, nuts_sampler=\"numpyro\", target_accept=0.98, random_seed=rng\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with matern_model:\n",
    "    ppc = pm.sample_posterior_predictive(matern_idata, random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean_ppc = ppc[\"posterior_predictive\"][\"likelihood\"].mean((\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the estimated function against the true function\n",
    "plt.plot(x, y_mean_ppc, c=\"k\", label=\"estimated function\")\n",
    "plt.scatter(x, y, label=\"true function\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GP to model the simulated data\n",
    "with pm.Model() as expquad_model:\n",
    "\n",
    "    eta = pm.Exponential(\"eta\", scale=10.0)\n",
    "    ls = pm.Lognormal(\"ls\", mu=0.5, sigma=0.75)\n",
    "    cov_func = eta**2 * pm.gp.cov.ExpQuad(input_dim=1, ls=ls)\n",
    "    gp = pm.gp.Latent(cov_func=cov_func)\n",
    "    s = gp.prior(\"s\", X=x[:, None])\n",
    "\n",
    "    measurement_error = pm.Exponential(\"measurement_error\", scale=5.0)\n",
    "    pm.Normal(\"likelihood\", mu=s, sigma=measurement_error, observed=y)\n",
    "    expquad_idata = pm.sample(\n",
    "        draws=2000, tune=2000, nuts_sampler=\"numpyro\", target_accept=0.98, random_seed=rng\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with expquad_model:\n",
    "    ppc = pm.sample_posterior_predictive(expquad_idata, random_seed=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean_ppc = ppc[\"posterior_predictive\"][\"likelihood\"].mean((\"chain\", \"draw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the estimated function against the true function\n",
    "plt.plot(x, y_mean_ppc, c=\"k\", label=\"estimated function\")\n",
    "plt.scatter(x, y, label=\"true function\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above figures. The Exponential Quadratic covariance function is too slow to capture the abrupt change but also overshoots the change due to being overly smooth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case-study walked us through how we can utilize an HSGP to include spatial information into our estimates. Specifically, we saw how we can validate our model specification, produce out-of-sample estimates, and how we can use the whole posterior distribution to make decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "* Adapted from {ref}`Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny` by Dr. Paula Moraga ([link](https://www.paulamoraga.com/book-geospatial/index.html)).\n",
    "### Acknowledgments\n",
    "* Bill Engels who encouraged, reviewed, and provided both feedback and code improvements to this example\n",
    "* Osvaldo A Martin, reviewed and provided valuable feedback that improved the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    ":::{bibliography}\n",
    ":filter: docname in docnames \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
