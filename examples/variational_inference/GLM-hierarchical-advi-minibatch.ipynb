{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM: Mini-batch ADVI on hierarchical regression model\n",
    "\n",
    ":::{post} Sept 23, 2021\n",
    ":tags: generalized linear model, hierarchical model, variational inference\n",
    ":category: intermediate\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Gaussian mixture models, (hierarchical) regression models have independent variables. These variables affect the likelihood function, but are not random variables. When using mini-batch, we should take care of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PYTENSOR_FLAGS=device=cpu, floatX=float32, warn_float64=ignore\n",
    "\n",
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(os.path.join(\"..\", \"data\", \"radon.csv\"))\n",
    "except FileNotFoundError:\n",
    "    data = pd.read_csv(pm.get_data(\"radon.csv\"))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_idx = data[\"county_code\"].values\n",
    "floor_idx = data[\"floor\"].values\n",
    "log_radon_idx = data[\"log_radon\"].values\n",
    "\n",
    "coords = {\"counties\": data.county.unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `log_radon_idx_t` is a dependent variable, while `floor_idx_t` and `county_idx_t` determine the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_radon_idx_t = pm.Minibatch(log_radon_idx, batch_size=100)\n",
    "floor_idx_t = pm.Minibatch(floor_idx, batch_size=100)\n",
    "county_idx_t = pm.Minibatch(county_idx, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as hierarchical_model:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_a = pm.Normal(\"mu_alpha\", mu=0.0, sigma=100**2)\n",
    "    sigma_a = pm.Uniform(\"sigma_alpha\", lower=0, upper=100)\n",
    "    mu_b = pm.Normal(\"mu_beta\", mu=0.0, sigma=100**2)\n",
    "    sigma_b = pm.Uniform(\"sigma_beta\", lower=0, upper=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept for each county, distributed around group mean `mu_a`. Above we just set `mu` and `sd` to a fixed value while here we plug in a common group distribution for all `a` and `b` (which are vectors with the same length as the number of unique counties in our example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    a = pm.Normal(\"alpha\", mu=mu_a, sigma=sigma_a, dims=\"counties\")\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    b = pm.Normal(\"beta\", mu=mu_b, sigma=sigma_b, dims=\"counties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model prediction of radon level `a[county_idx]` translates to `a[0, 0, 0, 1, 1, ...]`, we thus link multiple household measures of a county to its coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    radon_est = a[county_idx_t] + b[county_idx_t] * floor_idx_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we specify the likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    # Model error\n",
    "    eps = pm.Uniform(\"eps\", lower=0, upper=100)\n",
    "\n",
    "    # Data likelihood\n",
    "    radon_like = pm.Normal(\n",
    "        \"radon_like\", mu=radon_est, sigma=eps, observed=log_radon_idx_t, total_size=len(data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random variables `radon_like`, associated with `log_radon_idx_t`, should be given to the function for ADVI to denote that as observations in the likelihood term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, `minibatches` should include the three variables above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run ADVI with mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    approx = pm.fit(100_000, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)])\n",
    "\n",
    "idata_advi = approx.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the trace of ELBO and compare the result with MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(approx.hist);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the covariance matrix from the mean field approximation and use it as the scaling matrix for the NUTS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = approx.cov.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can generate samples (one for each chain) to use as the starting points for the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 4\n",
    "sample = approx.sample(return_inferencedata=False, size=n_chains)\n",
    "start_dict = list(sample[i] for i in range(n_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference button (TM)!\n",
    "with pm.Model(coords=coords):\n",
    "    mu_a = pm.Normal(\"mu_alpha\", mu=0.0, sigma=100**2)\n",
    "    sigma_a = pm.Uniform(\"sigma_alpha\", lower=0, upper=100)\n",
    "    mu_b = pm.Normal(\"mu_beta\", mu=0.0, sigma=100**2)\n",
    "    sigma_b = pm.Uniform(\"sigma_beta\", lower=0, upper=100)\n",
    "\n",
    "    a = pm.Normal(\"alpha\", mu=mu_a, sigma=sigma_a, dims=\"counties\")\n",
    "    b = pm.Normal(\"beta\", mu=mu_b, sigma=sigma_b, dims=\"counties\")\n",
    "\n",
    "    # Model error\n",
    "    eps = pm.Uniform(\"eps\", lower=0, upper=100)\n",
    "\n",
    "    radon_est = a[county_idx] + b[county_idx] * floor_idx\n",
    "\n",
    "    radon_like = pm.Normal(\"radon_like\", mu=radon_est, sigma=eps, observed=log_radon_idx)\n",
    "\n",
    "    # essentially, this is what init='advi' does\n",
    "    step = pm.NUTS(scaling=scaling, is_cov=True)\n",
    "    hierarchical_trace = pm.sample(draws=2000, step=step, chains=n_chains, initvals=start_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(\n",
    "    data=[idata_advi, hierarchical_trace],\n",
    "    var_names=[\"~alpha\", \"~beta\"],\n",
    "    data_labels=[\"ADVI\", \"NUTS\"],\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p xarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d54ac2181a459dda88915244fad851391a089975b391e6a024564737e40ca82a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
