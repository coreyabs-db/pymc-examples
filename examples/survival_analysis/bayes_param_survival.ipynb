{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(bayes_param_survival)=\n",
    "\n",
    "# Bayesian Parametric Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels import datasets\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Survival analysis](https://en.wikipedia.org/wiki/Survival_analysis) studies the distribution of the time between when a subject comes under observation and when that subject experiences an event of interest.  One of the fundamental challenges of survival analysis (which also makes is mathematically interesting) is that, in general, not every subject will experience the event of interest before we conduct our analysis.  In more concrete terms, if we are studying the time between cancer treatment and death (as we will in this post), we will often want to analyze our data before every subject has died.  This phenomenon is called [censoring](https://en.wikipedia.org/wiki/Censoring_(statistics)) and is fundamental to survival analysis.\n",
    "\n",
    "\n",
    "This post illustrates a parametric approach to Bayesian survival analysis in PyMC. Parametric models of survival are simpler to both implement and understand than semiparametric models; statistically, they are also more [powerful](https://en.wikipedia.org/wiki/Power_(statistics)) than non- or semiparametric methods when they are correctly specified. For an example of a [semiparametric](https://en.wikipedia.org/wiki/Semiparametric_model) [Cox proportional hazards model](https://en.wikipedia.org/wiki/Proportional_hazards_model#The_Cox_model), you can read this [blogpost](http://austinrochford.com/posts/2015-10-05-bayes-survival.html), but be aware that the post used and old version of PyMC and that Implementing a semiparametric model in PyMC involved some fairly complex numpy code and nonobvious probability theory equivalences.\n",
    "\n",
    "We will analyze the [mastectomy data](https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/mastectomy.html) from `R`'s [`HSAUR`](https://cran.r-project.org/web/packages/HSAUR/index.html) package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "blue, green, red, purple, gold, teal = sns.color_palette(n_colors=6)\n",
    "\n",
    "pct_formatter = StrMethodFormatter(\"{x:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.get_rdataset(\"mastectomy\", \"HSAUR\", cache=True).data.assign(\n",
    "    metastized=lambda df: 1.0 * (df.metastized == \"yes\"), event=lambda df: 1.0 * df.event\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `time` represents the survival time for a breast cancer patient after a mastectomy, measured in months.  The column `event` indicates whether or not the observation is censored.  If `event` is one, the patient's death was observed during the study; if `event` is zero,  the patient lived past the end of the study and their survival time is censored.  The column `metastized` indicates whether the cancer had [metastized](https://en.wikipedia.org/wiki/Metastasis) prior to the mastectomy.  In this post, we will use Bayesian parametric survival regression to quantify the difference in survival times for patients whose cancer had and had not metastized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerated failure time models\n",
    "\n",
    "[Accelerated failure time models](https://en.wikipedia.org/wiki/Accelerated_failure_time_model) are the most common type of parametric survival regression models.  The fundamental quantity of survival analysis is the [survival function](https://en.wikipedia.org/wiki/Survival_function); if $T$ is the random variable representing the time to the event in question, the survival function is $S(t) = P(T > t)$.  Accelerated failure time models incorporate covariates $\\mathbf{x}$ into the survival function as\n",
    "\n",
    "$$S(t\\ |\\ \\beta, \\mathbf{x}) = S_0\\left(\\exp\\left(\\beta^{\\top} \\mathbf{x}\\right) \\cdot t\\right),$$\n",
    "\n",
    "where $S_0(t)$ is a fixed baseline survival function.  These models are called \"accelerated failure time\" because, when $\\beta^{\\top} \\mathbf{x} > 0$, $\\exp\\left(\\beta^{\\top} \\mathbf{x}\\right) \\cdot t > t$, so the effect of the covariates is to accelerate the _effective_ passage of time for the individual in question.  The following plot illustrates this phenomenon using an exponential survival function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = sp.stats.expon.sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "t = np.linspace(0, 10, 100)\n",
    "\n",
    "ax.plot(t, S0(5 * t), label=r\"$\\beta^{\\top} \\mathbf{x} = \\log\\ 5$\")\n",
    "ax.plot(t, S0(2 * t), label=r\"$\\beta^{\\top} \\mathbf{x} = \\log\\ 2$\")\n",
    "ax.plot(t, S0(t), label=r\"$\\beta^{\\top} \\mathbf{x} = 0$ ($S_0$)\")\n",
    "ax.plot(t, S0(0.5 * t), label=r\"$\\beta^{\\top} \\mathbf{x} = -\\log\\ 2$\")\n",
    "ax.plot(t, S0(0.2 * t), label=r\"$\\beta^{\\top} \\mathbf{x} = -\\log\\ 5$\")\n",
    "\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_xlabel(r\"$t$\")\n",
    "\n",
    "ax.yaxis.set_major_formatter(pct_formatter)\n",
    "ax.set_ylim(-0.025, 1)\n",
    "ax.set_ylabel(r\"Survival probability, $S(t\\ |\\ \\beta, \\mathbf{x})$\")\n",
    "\n",
    "ax.legend(loc=1)\n",
    "ax.set_title(\"Accelerated failure times\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accelerated failure time models are equivalent to log-linear models for $T$,\n",
    "\n",
    "$$Y = \\log T = \\beta^{\\top} \\mathbf{x} + \\varepsilon.$$\n",
    "\n",
    "A choice of distribution for the error term $\\varepsilon$ determines baseline survival function, $S_0$, of the accelerated failure time model.  The following table shows the correspondence between the distribution of $\\varepsilon$ and $S_0$ for several common accelerated failure time models.\n",
    "\n",
    "| Log-linear error distribution ($\\varepsilon$) | Baseline survival function ($S_0$) |\n",
    "|-----------------------------------------------|-------------------------------------|\n",
    "| [Normal](https://en.wikipedia.org/wiki/Normal_distribution) | [Log-normal](https://en.wikipedia.org/wiki/Log-normal_distribution) |\n",
    "| Extreme value ([Gumbel](https://en.wikipedia.org/wiki/Gumbel_distribution)) | [Weibull](https://en.wikipedia.org/wiki/Weibull_distribution) |\n",
    "| [Logistic](https://en.wikipedia.org/wiki/Logistic_distribution) | [Log-logistic](https://en.wikipedia.org/wiki/Log-logistic_distribution) |\n",
    "\n",
    "Accelerated failure time models are conventionally named after their baseline survival function, $S_0$.  The rest of this post will show how to implement Weibull and log-logistic survival regression models in PyMC using the mastectomy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weibull survival regression\n",
    "\n",
    "In this example, the covariates are $\\mathbf{x}_i = \\left(1\\ x^{\\textrm{met}}_i\\right)^{\\top}$, where\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x^{\\textrm{met}}_i\n",
    "    & = \\begin{cases}\n",
    "        0 & \\textrm{if the } i\\textrm{-th patient's cancer had not metastized} \\\\\n",
    "        1 & \\textrm{if the } i\\textrm{-th patient's cancer had metastized}\n",
    "    \\end{cases}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We construct the matrix of covariates $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patient, _ = df.shape\n",
    "\n",
    "X = np.empty((n_patient, 2))\n",
    "X[:, 0] = 1.0\n",
    "X[:, 1] = df.metastized\n",
    "\n",
    "with pm.Model() as weibull_model:\n",
    "    predictors = pm.Data(\"predictors\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of the data is specified in two parts, one for uncensored samples, and one for censored samples.  Since $Y = \\eta + \\varepsilon$, and $\\varepsilon \\sim \\textrm{Gumbel}(0, s)$, $Y \\sim \\textrm{Gumbel}(\\eta, s)$.  For the uncensored survival times, the likelihood is implemented as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    censored = pm.Data(\"censored\", df.event.values == 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the observed times to the log scale and standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(df.time.values)\n",
    "y_std = (y - y.mean()) / y.std()\n",
    "\n",
    "with weibull_model:\n",
    "    y_obs = pm.Data(\"y_obs\", y_std[df.event.values == 1.0])\n",
    "    y_cens = pm.Data(\"y_cens\", y_std[df.event.values == 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place independent, vague normal prior distributions on the regression coefficients,\n",
    "\n",
    "$$\\beta \\sim N(0, 5^2 I_2).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    beta = pm.Normal(\"beta\", mu=0.0, sigma=5.0, shape=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariates, $\\mathbf{x}$, affect value of $Y = \\log T$ through $\\eta = \\beta^{\\top} \\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    eta = beta.dot(predictors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Weibull regression, we use\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\varepsilon\n",
    "        & \\sim \\textrm{Gumbel}(0, s) \\\\\n",
    "    s\n",
    "        & \\sim \\textrm{HalfNormal(5)}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    s = pm.HalfNormal(\"s\", 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    events = pm.Gumbel(\"events\", eta[~censored], s, observed=y_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For censored observations, we only know that their true survival time exceeded the total time that they were under observation.  This probability is given by the survival function of the Gumbel distribution,\n",
    "\n",
    "$$P(Y \\geq y) = 1 - \\exp\\left(-\\exp\\left(-\\frac{y - \\mu}{s}\\right)\\right).$$\n",
    "\n",
    "This survival function is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_sf(y, mu, sigma):\n",
    "    return 1.0 - pt.exp(-pt.exp(-(y - mu) / sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now specify the likelihood for the censored observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    censored_like = pm.Potential(\"censored_like\", gumbel_sf(y_cens, eta[censored], s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now sample from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 845199  # from random.org, for reproducibility\n",
    "\n",
    "SAMPLE_KWARGS = {\"chains\": 4, \"tune\": 1000, \"random_seed\": [SEED + i for i in range(4)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    weibull_trace = pm.sample(**SAMPLE_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The energy plot and Bayesian fraction of missing information give no cause for concern about poor mixing in NUTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_energy(weibull_trace, fill_color=(\"C0\", \"C1\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\hat{R}$ statistics also indicate convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(np.max(gr_stats) for gr_stats in az.rhat(weibull_trace).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot posterior distributions of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(weibull_trace, figsize=(10, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are somewhat interesting (especially the fact that the posterior of $\\beta_1$ is fairly well-separated from zero), but the posterior predictive survival curves will be much more interpretable.\n",
    "\n",
    "The advantage of using `Data` variables is that we can now change their values to perform posterior predictive sampling.  For posterior prediction, we set $X$ to have two rows, one for a subject whose cancer had not metastized and one for a subject whose cancer had metastized.  Since we want to predict actual survival times, none of the posterior predictive rows are censored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp = np.empty((2, 2))\n",
    "X_pp[:, 0] = 1.0\n",
    "X_pp[:, 1] = [0, 1]\n",
    "\n",
    "cens_pp = np.repeat(False, 2)\n",
    "\n",
    "with weibull_model:\n",
    "    pm.set_data(\n",
    "        {\"predictors\": X_pp, \"censored\": cens_pp, \"y_obs\": np.zeros(2), \"y_cens\": np.zeros(0)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with weibull_model:\n",
    "    pp_weibull_trace = pm.sample_posterior_predictive(weibull_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior predictive survival times show that, on average, patients whose cancer had not metastized survived longer than those whose cancer had metastized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_plot = np.linspace(0, 230, 100)\n",
    "\n",
    "weibull_pp_surv = np.greater_equal.outer(\n",
    "    np.exp(\n",
    "        y.mean()\n",
    "        + y.std() * az.extract(pp_weibull_trace.posterior_predictive[\"events\"])[\"events\"].values\n",
    "    ),\n",
    "    t_plot,\n",
    ")\n",
    "weibull_pp_surv_mean = weibull_pp_surv.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "\n",
    "ax.plot(t_plot, weibull_pp_surv_mean[0], c=blue, label=\"Not metastized\")\n",
    "ax.plot(t_plot, weibull_pp_surv_mean[1], c=red, label=\"Metastized\")\n",
    "\n",
    "ax.set_xlim(0, 230)\n",
    "ax.set_xlabel(\"Weeks since mastectomy\")\n",
    "\n",
    "ax.set_ylim(top=1)\n",
    "ax.yaxis.set_major_formatter(pct_formatter)\n",
    "ax.set_ylabel(\"Survival probability\")\n",
    "\n",
    "ax.legend(loc=1)\n",
    "ax.set_title(\"Weibull survival regression model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-logistic survival regression\n",
    "\n",
    "Other accelerated failure time models can be specified in a modular way by changing the prior distribution on $\\varepsilon$.  A log-logistic model corresponds to a [logistic](https://en.wikipedia.org/wiki/Logistic_distribution) prior on $\\varepsilon$.  Most of the model specification is the same as for the Weibull model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as log_logistic_model:\n",
    "    predictors = pm.Data(\"predictors\", X)\n",
    "    censored = pm.Data(\"censored\", df.event.values == 0.0)\n",
    "    y_obs = pm.Data(\"y_obs\", y_std[df.event.values == 1.0])\n",
    "    y_cens = pm.Data(\"y_cens\", y_std[df.event.values == 0.0])\n",
    "\n",
    "    beta = pm.Normal(\"beta\", 0.0, 5.0, shape=2)\n",
    "    eta = beta.dot(predictors.T)\n",
    "\n",
    "    s = pm.HalfNormal(\"s\", 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the prior $\\varepsilon \\sim \\textrm{Logistic}(0, s)$.  The survival function of the logistic distribution is\n",
    "\n",
    "$$P(Y \\geq y) = 1 - \\frac{1}{1 + \\exp\\left(-\\left(\\frac{y - \\mu}{s}\\right)\\right)},$$\n",
    "\n",
    "so we get the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_sf(y, mu, s):\n",
    "    return 1.0 - pm.math.sigmoid((y - mu) / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with log_logistic_model:\n",
    "    events = pm.Logistic(\"events\", eta[~censored], s, observed=y_obs)\n",
    "    censored_like = pm.Potential(\"censored_like\", logistic_sf(y_cens, eta[censored], s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now sample from the log-logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with log_logistic_model:\n",
    "    log_logistic_trace = pm.sample(**SAMPLE_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the sampling diagnostics look good for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_energy(log_logistic_trace, fill_color=(\"C0\", \"C1\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(np.max(gr_stats) for gr_stats in az.rhat(log_logistic_trace).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we calculate the posterior expected survival functions for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with log_logistic_model:\n",
    "    pm.set_data(\n",
    "        {\"predictors\": X_pp, \"censored\": cens_pp, \"y_obs\": np.zeros(2), \"y_cens\": np.zeros(0)}\n",
    "    )\n",
    "    pp_log_logistic_trace = pm.sample_posterior_predictive(log_logistic_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_logistic_pp_surv = np.greater_equal.outer(\n",
    "    np.exp(\n",
    "        y.mean()\n",
    "        + y.std()\n",
    "        * az.extract(pp_log_logistic_trace.posterior_predictive[\"events\"])[\"events\"].values\n",
    "    ),\n",
    "    t_plot,\n",
    ")\n",
    "log_logistic_pp_surv_mean = log_logistic_pp_surv.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.plot(t_plot, weibull_pp_surv_mean[0], c=blue, label=\"Weibull, not metastized\")\n",
    "ax.plot(t_plot, weibull_pp_surv_mean[1], c=red, label=\"Weibull, metastized\")\n",
    "\n",
    "ax.plot(t_plot, log_logistic_pp_surv_mean[0], \"--\", c=blue, label=\"Log-logistic, not metastized\")\n",
    "ax.plot(t_plot, log_logistic_pp_surv_mean[1], \"--\", c=red, label=\"Log-logistic, metastized\")\n",
    "\n",
    "ax.set_xlim(0, 230)\n",
    "ax.set_xlabel(\"Weeks since mastectomy\")\n",
    "\n",
    "ax.set_ylim(top=1)\n",
    "ax.yaxis.set_major_formatter(pct_formatter)\n",
    "ax.set_ylabel(\"Survival probability\")\n",
    "\n",
    "ax.legend(loc=1)\n",
    "ax.set_title(\"Weibull and log-logistic\\nsurvival regression models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post has been a short introduction to implementing parametric survival regression models in PyMC with a fairly simple data set.  The modular nature of probabilistic programming with PyMC should make it straightforward to generalize these techniques to more complex and interesting data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Originally authored as a blog post by [Austin Rochford](https://austinrochford.com/posts/2017-10-02-bayes-param-survival.html) on October 2, 2017.\n",
    "- Updated by [George Ho](https://eigenfoo.xyz/) on July 18, 2018.\n",
    "- Updated by @fonnesbeck on September 11, 2024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
