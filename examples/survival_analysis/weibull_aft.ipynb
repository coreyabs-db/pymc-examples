{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(weibull_aft)=\n",
    "\n",
    "# Reparameterizing the Weibull Accelerated Failure Time Model\n",
    "\n",
    ":::{post} January 17, 2023\n",
    ":tags: censored, survival analysis, weibull\n",
    ":category: intermediate, how-to\n",
    ":author: Junpeng Lao, George Ho, Chris Fonnesbeck\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The {ref}`previous example notebook on Bayesian parametric survival analysis <bayes_param_survival_pymc3>` introduced two different accelerated failure time (AFT) models: Weibull and log-linear. In this notebook, we present three different parameterizations of the Weibull AFT model.\n",
    "\n",
    "The data set we'll use is the `flchain` R data set, which comes from a medical study investigating the effect of serum free light chain (FLC) on lifespan. Read the full documentation of the data by running:\n",
    "\n",
    "`print(sm.datasets.get_rdataset(package='survival', dataname='flchain').__doc__)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and clean data\n",
    "data = (\n",
    "    sm.datasets.get_rdataset(package=\"survival\", dataname=\"flchain\")\n",
    "    .data.sample(500)  # Limit ourselves to 500 observations\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.futime.values\n",
    "censored = ~data[\"death\"].values.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pm.Potential`\n",
    "\n",
    "We have an unique problem when modelling censored data. Strictly speaking, we don't have any _data_ for censored values: we only know the _number_ of values that were censored. How can we include this information in our model?\n",
    "\n",
    "One way do this is by making use of `pm.Potential`. The [PyMC2 docs](https://pymc-devs.github.io/pymc/modelbuilding.html#the-potential-class) explain its usage very well. Essentially, declaring `pm.Potential('x', logp)` will add `logp` to the log-likelihood of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization 1\n",
    "\n",
    "This parameterization is an intuitive, straightforward parameterization of the Weibull survival function. This is probably the first parameterization to come to one's mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_lccdf(x, alpha, beta):\n",
    "    \"\"\"Log complementary cdf of Weibull distribution.\"\"\"\n",
    "    return -((x / beta) ** alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_1:\n",
    "    alpha_sd = 10.0\n",
    "\n",
    "    mu = pm.Normal(\"mu\", mu=0, sigma=100)\n",
    "    alpha_raw = pm.Normal(\"a0\", mu=0, sigma=0.1)\n",
    "    alpha = pm.Deterministic(\"alpha\", pt.exp(alpha_sd * alpha_raw))\n",
    "    beta = pm.Deterministic(\"beta\", pt.exp(mu / alpha))\n",
    "\n",
    "    y_obs = pm.Weibull(\"y_obs\", alpha=alpha, beta=beta, observed=y[~censored])\n",
    "    y_cens = pm.Potential(\"y_cens\", weibull_lccdf(y[censored], alpha, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_1:\n",
    "    # Change init to avoid divergences\n",
    "    data_1 = pm.sample(target_accept=0.9, init=\"adapt_diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data_1, var_names=[\"alpha\", \"beta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(data_1, var_names=[\"alpha\", \"beta\"], round_to=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization 2\n",
    "\n",
    "Note that, confusingly, `alpha` is now called `r`, and `alpha` denotes a prior; we maintain this notation to stay faithful to the original implementation in Stan. In this parameterization, we still model the same parameters `alpha` (now `r`) and `beta`.\n",
    "\n",
    "For more information, see [this Stan example model](https://github.com/stan-dev/example-models/blob/5e9c5055dcea78ad756a6fb9b3ff9a77a0a4c22b/bugs_examples/vol1/kidney/kidney.stan) and [the corresponding documentation](https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/WinBUGS_Vol1.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_2:\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n",
    "    r = pm.Gamma(\"r\", alpha=1, beta=0.001, testval=0.25)\n",
    "    beta = pm.Deterministic(\"beta\", pt.exp(-alpha / r))\n",
    "\n",
    "    y_obs = pm.Weibull(\"y_obs\", alpha=r, beta=beta, observed=y[~censored])\n",
    "    y_cens = pm.Potential(\"y_cens\", weibull_lccdf(y[censored], r, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_2:\n",
    "    # Increase target_accept to avoid divergences\n",
    "    data_2 = pm.sample(target_accept=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data_2, var_names=[\"r\", \"beta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(data_2, var_names=[\"r\", \"beta\"], round_to=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization 3\n",
    "\n",
    "In this parameterization, we model the log-linear error distribution with a Gumbel distribution instead of modelling the survival function directly. For more information, see [this blog post](http://austinrochford.com/posts/2017-10-02-bayes-param-survival.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logtime = np.log(y)\n",
    "\n",
    "\n",
    "def gumbel_sf(y, mu, sigma):\n",
    "    \"\"\"Gumbel survival function.\"\"\"\n",
    "    return 1.0 - pt.exp(-pt.exp(-(y - mu) / sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_3:\n",
    "    s = pm.HalfNormal(\"s\", tau=5.0)\n",
    "    gamma = pm.Normal(\"gamma\", mu=0, sigma=5)\n",
    "\n",
    "    y_obs = pm.Gumbel(\"y_obs\", mu=gamma, beta=s, observed=logtime[~censored])\n",
    "    y_cens = pm.Potential(\"y_cens\", gumbel_sf(y=logtime[censored], mu=gamma, sigma=s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_3:\n",
    "    # Change init to avoid divergences\n",
    "    data_3 = pm.sample(init=\"adapt_diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(data_3, round_to=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Originally collated by [Junpeng Lao](https://junpenglao.xyz/) on Apr 21, 2018. See original code [here](https://github.com/junpenglao/Planet_Sakaar_Data_Science/blob/65447fdb431c78b15fbeaef51b8c059f46c9e8d6/PyMC3QnA/discourse_1107.ipynb).\n",
    "- Authored and ported to Jupyter notebook by [George Ho](https://eigenfoo.xyz/) on Jul 15, 2018.\n",
    "- Updated for compatibility with PyMC v5 by Chris Fonnesbeck on Jan 16, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{include} ../page_footer.md\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "970ac73df0f14d7a1f980febd250c4ded990984ec0e2432b12dcbf556b464244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
